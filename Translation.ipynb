{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Whereamiactually/lyceumcompling11/blob/main/Translation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Машинный перевод\n",
        "*(частично материалы курса ФиКЛ, спасибо авторам и Татьяне Казаковой)*"
      ],
      "metadata": {
        "id": "royV6GP9xr16"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Правила\n",
        "Традиционно: можно долго прописывать правила (соответствия слов, трансформацию синтаксиса и т.д.)\n",
        "\n",
        "### Статистический машинный перевод\n",
        "\n",
        "Наиболее частый - PBMT - phrase-based machine translation. Есть пословный, синтаксический и другие. В парах предложений в большом корпусе статистически определяются соответствия кусочков предложений (фраз) и эта информация используется для перевода нового текста. Часто используется как базовая модель, если нет достаточного корпуса для нейронного.\n",
        "\n",
        "### NMT - neural machine translation\n",
        "\n",
        "Обучается нейронная сеть на большом корпусе, которая учится предсказывать наилучший перевод.\n",
        "\n",
        "Если не правила, нам нужны параллельные корпуса с выравниванием по предложению, например, [OPUS](https://opus.nlpl.eu/).\n",
        "\n"
      ],
      "metadata": {
        "id": "cVHQK8kxwxwB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Как оценивается качество?\n",
        "\n",
        "Например, с помощью BLEU (bilingual evaluation understudy) - доля слов или чаще n-грамм, которые совпали в варианте перевода и ответами (0 - все плохо, 1 - отлично, но так не бывает даже у человека). Считается, что 4-граммы наиболее хорошо описывают хорошую человеческую речь."
      ],
      "metadata": {
        "id": "_JENHHDw0y8W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Попробуем пословное выравнивание"
      ],
      "metadata": {
        "id": "AyE-eujF-pce"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Будет использовать программу fast_align."
      ],
      "metadata": {
        "id": "OTORGvFc-xx5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Qy69Nub-wCAJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8782711a-4752-4dbb-dd08-3eeb664bdfa3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'fast_align'...\n",
            "remote: Enumerating objects: 213, done.\u001b[K\n",
            "remote: Counting objects: 100% (9/9), done.\u001b[K\n",
            "remote: Compressing objects: 100% (7/7), done.\u001b[K\n",
            "remote: Total 213 (delta 2), reused 4 (delta 2), pack-reused 204\u001b[K\n",
            "Receiving objects: 100% (213/213), 70.68 KiB | 540.00 KiB/s, done.\n",
            "Resolving deltas: 100% (110/110), done.\n"
          ]
        }
      ],
      "source": [
        "! git clone https://github.com/clab/fast_align.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mkdir /content/fast_align/build # создаем папку для сборки"
      ],
      "metadata": {
        "id": "pqanA1E81iJl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pwd\n",
        "# переходим в папку\n",
        "%cd fast_align/build\n",
        "! pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMDAeGgw4I1Y",
        "outputId": "c20984ca-6005-45dc-8001-a732821119a0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n",
            "/content/fast_align/build\n",
            "/content/fast_align/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! cmake .. # собираем"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teNlG1El5BU-",
        "outputId": "b01f48f0-523d-4e56-8ebb-36f9a33d2a74"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mCMake Warning (dev) at CMakeLists.txt:1 (project):\n",
            "  cmake_minimum_required() should be called prior to this top-level project()\n",
            "  call.  Please see the cmake-commands(7) manual for usage documentation of\n",
            "  both commands.\n",
            "This warning is for project developers.  Use -Wno-dev to suppress it.\n",
            "\u001b[0m\n",
            "-- The C compiler identification is GNU 11.4.0\n",
            "-- The CXX compiler identification is GNU 11.4.0\n",
            "-- Detecting C compiler ABI info\n",
            "-- Detecting C compiler ABI info - done\n",
            "-- Check for working C compiler: /usr/bin/cc - skipped\n",
            "-- Detecting C compile features\n",
            "-- Detecting C compile features - done\n",
            "-- Detecting CXX compiler ABI info\n",
            "-- Detecting CXX compiler ABI info - done\n",
            "-- Check for working CXX compiler: /usr/bin/c++ - skipped\n",
            "-- Detecting CXX compile features\n",
            "-- Detecting CXX compile features - done\n",
            "\u001b[0mCMake Deprecation Warning at CMakeLists.txt:2 (cmake_minimum_required):\n",
            "  Compatibility with CMake < 3.5 will be removed from a future version of\n",
            "  CMake.\n",
            "\n",
            "  Update the VERSION argument <min> value or use a ...<max> suffix to tell\n",
            "  CMake that the project does not need compatibility with older versions.\n",
            "\n",
            "\u001b[0m\n",
            "-- Could NOT find SparseHash (missing: SPARSEHASH_INCLUDE_DIR) \n",
            "-- Configuring done (1.5s)\n",
            "-- Generating done (0.0s)\n",
            "-- Build files have been written to: /content/fast_align/build\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! make # собираем"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPd7M_0S5E8c",
        "outputId": "2ba0b31d-b6d4-4118-bea1-f56a5e91345c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 16%] \u001b[32mBuilding CXX object CMakeFiles/fast_align.dir/src/fast_align.cc.o\u001b[0m\n",
            "[ 33%] \u001b[32mBuilding CXX object CMakeFiles/fast_align.dir/src/ttables.cc.o\u001b[0m\n",
            "[ 50%] \u001b[32m\u001b[1mLinking CXX executable fast_align\u001b[0m\n",
            "[ 50%] Built target fast_align\n",
            "[ 66%] \u001b[32mBuilding CXX object CMakeFiles/atools.dir/src/alignment_io.cc.o\u001b[0m\n",
            "[ 83%] \u001b[32mBuilding CXX object CMakeFiles/atools.dir/src/atools.cc.o\u001b[0m\n",
            "[100%] \u001b[32m\u001b[1mLinking CXX executable atools\u001b[0m\n",
            "[100%] Built target atools\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# возвращаемся в домашнюю папку\n",
        "%cd ..\n",
        "%cd .."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nr0eIwqX4AOD",
        "outputId": "12962e59-c522-40b5-9865-a8663bb1519a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/fast_align\n",
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Скачиваем с OPUS небольшой корпус книг."
      ],
      "metadata": {
        "id": "hWd9gBC__e4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! wget https://object.pouta.csc.fi/OPUS-Books/v1/moses/en-ru.txt.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qwBqt0vl1mBq",
        "outputId": "22f7b53f-5784-4314-839c-f3af09a964ab"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-20 08:38:32--  https://object.pouta.csc.fi/OPUS-Books/v1/moses/en-ru.txt.zip\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1613419 (1.5M) [application/zip]\n",
            "Saving to: ‘en-ru.txt.zip’\n",
            "\n",
            "en-ru.txt.zip       100%[===================>]   1.54M   901KB/s    in 1.7s    \n",
            "\n",
            "2023-10-20 08:38:36 (901 KB/s) - ‘en-ru.txt.zip’ saved [1613419/1613419]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! unzip en-ru.txt.zip"
      ],
      "metadata": {
        "id": "LipSHC_S5fFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68d5636b-5348-4ca1-f6f7-744d50eb7f5a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  en-ru.txt.zip\n",
            "  inflating: Books.en-ru.en          \n",
            "  inflating: Books.en-ru.ru          \n",
            "  inflating: Books.en-ru.ids         \n",
            "  inflating: README                  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Преобразуем данные в тот вид, в котором они принимаются программой."
      ],
      "metadata": {
        "id": "S7V9339y_kMc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! paste Books.en-ru.en Books.en-ru.ru -d \"\\t\" | sed 's/\\t/ ||| /' > Books.en-ru"
      ],
      "metadata": {
        "id": "3kNUyARo13E7"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head Books.en-ru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iOpgM8OQ14kR",
        "outputId": "ce473bc4-1c53-48b1-ffcd-b392e4305f24"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anna Karenina ||| Анна Каренина\n",
            "Leo Tolstoy ||| Толстой Лев Николаевич\n",
            "Vengeance is mine; I will repay. ||| Мне отмщение, и аз воздам\n",
            "VOLUME ONE PART I ||| ЧАСТЬ ПЕРВАЯ\n",
            "CHAPTER I ||| I\n",
            "ALL HAPPY FAMILIES resemble one another, but each unhappy family is unhappy in its own way. ||| Все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему.\n",
            "Everything was upset in the Oblonskys' house. ||| Все смешалось в доме Облонских.\n",
            "The wife had discovered an intrigue between her husband and their former French governess, and declared that she would not continue to live under the same roof with him. ||| Жена узнала, что муж был в связи с бывшею в их доме француженкою-гувернанткой, и объявила мужу, что не может жить с ним в одном доме.\n",
            "This state of things had now lasted for three days, and not only the husband and wife but the rest of the family and the whole household suffered from it. ||| Положение это продолжалось уже третий день и мучительно чувствовалось и самими супругами, и всеми членами семьи, и домочадцами.\n",
            "They all felt that there was no sense in their living together, and that any group of people who had met together by chance at an inn would have had more in common than they. ||| Все члены семьи и домочадцы чувствовали, что нет смысла в их сожительстве и что на каждом постоялом дворе случайно сошедшиеся люди более связаны между собой, чем они, члены семьи и домочадцы Облонских.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! mv ./fast_align ./fast_align_git # переименуем папку, а то она будет с таким же именем"
      ],
      "metadata": {
        "id": "KxeCuPos19uq"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! cp ./fast_align_git/build/fast_align ./fast_align\n",
        "! cp ./fast_align_git/build/atools ./atools"
      ],
      "metadata": {
        "id": "-rs0bzTB1__s"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! ./fast_align -i Books.en-ru -d -o -v > forward.align"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Udc2WrkX2CRO",
        "outputId": "e6306c76-d031-4b86-d209-30ba64d49e7e"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARG=i\n",
            "ARG=d\n",
            "ARG=o\n",
            "ARG=v\n",
            "INITIAL PASS \n",
            ".................\n",
            "expected target length = source length * 0.86155\n",
            "ITERATION 1\n",
            ".................\n",
            "  log_e likelihood: -5.8083e+06\n",
            "  log_2 likelihood: -8.3796e+06\n",
            "     cross entropy: 29.8974\n",
            "        perplexity: 1e+09\n",
            "      posterior p0: 0.08\n",
            " posterior al-feat: -0.174998\n",
            "       size counts: 1614\n",
            "ITERATION 2\n",
            ".................\n",
            "  log_e likelihood: -2.28139e+06\n",
            "  log_2 likelihood: -3.29134e+06\n",
            "     cross entropy: 11.7431\n",
            "        perplexity: 3427.88\n",
            "      posterior p0: 0.0906316\n",
            " posterior al-feat: -0.117567\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.209743 (tension=4)\n",
            "  2  model al-feat: -0.164009 (tension=5.84353)\n",
            "  3  model al-feat: -0.147483 (tension=6.77237)\n",
            "  4  model al-feat: -0.138632 (tension=7.37069)\n",
            "  5  model al-feat: -0.133146 (tension=7.79201)\n",
            "  6  model al-feat: -0.12946 (tension=8.1036)\n",
            "  7  model al-feat: -0.126852 (tension=8.34148)\n",
            "  8  model al-feat: -0.124936 (tension=8.52718)\n",
            "     final tension: 8.67458\n",
            "ITERATION 3\n",
            ".................\n",
            "  log_e likelihood: -1.44853e+06\n",
            "  log_2 likelihood: -2.08979e+06\n",
            "     cross entropy: 7.45611\n",
            "        perplexity: 175.595\n",
            "      posterior p0: 0.0551811\n",
            " posterior al-feat: -0.0918304\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.123491 (tension=8.67458)\n",
            "  2  model al-feat: -0.118038 (tension=9.3078)\n",
            "  3  model al-feat: -0.114475 (tension=9.83195)\n",
            "  4  model al-feat: -0.112143 (tension=10.2848)\n",
            "  5  model al-feat: -0.110706 (tension=10.6911)\n",
            "  6  model al-feat: -0.11 (tension=11.0686)\n",
            "  7  model al-feat: -0.109978 (tension=11.432)\n",
            "  8  model al-feat: -0.110707 (tension=11.7949)\n",
            "     final tension: 12.1725\n",
            "ITERATION 4\n",
            ".................\n",
            "  log_e likelihood: -1.34051e+06\n",
            "  log_2 likelihood: -1.93395e+06\n",
            "     cross entropy: 6.9001\n",
            "        perplexity: 119.437\n",
            "      posterior p0: 0.0527672\n",
            " posterior al-feat: -0.084793\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.11241 (tension=12.1725)\n",
            "  2  model al-feat: -0.117057 (tension=12.7248)\n",
            "  3  model al-feat: -0.126798 (tension=13.3701)\n",
            "  4  model al-feat: -0.142648 (tension=14)\n",
            "  5  model al-feat: -0.142648 (tension=14)\n",
            "  6  model al-feat: -0.142648 (tension=14)\n",
            "  7  model al-feat: -0.142648 (tension=14)\n",
            "  8  model al-feat: -0.142648 (tension=14)\n",
            "     final tension: 14\n",
            "ITERATION 5 (FINAL)\n",
            ".................\n",
            "  log_e likelihood: -1.31688e+06\n",
            "  log_2 likelihood: -1.89986e+06\n",
            "     cross entropy: 6.77846\n",
            "        perplexity: 109.779\n",
            "      posterior p0: 0\n",
            " posterior al-feat: 0\n",
            "       size counts: 1614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./fast_align -i Books.en-ru -d -o -v -r > reverse.align"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Ah2Hegc2Emh",
        "outputId": "563e7900-aad4-4493-9ed5-f8a8072dbe23"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ARG=i\n",
            "ARG=d\n",
            "ARG=o\n",
            "ARG=v\n",
            "ARG=r\n",
            "INITIAL PASS \n",
            ".................\n",
            "expected target length = source length * 1.26205\n",
            "ITERATION 1\n",
            ".................\n",
            "  log_e likelihood: -7.05339e+06\n",
            "  log_2 likelihood: -1.01759e+07\n",
            "     cross entropy: 29.8974\n",
            "        perplexity: 1e+09\n",
            "      posterior p0: 0.08\n",
            " posterior al-feat: -0.172934\n",
            "       size counts: 1614\n",
            "ITERATION 2\n",
            ".................\n",
            "  log_e likelihood: -2.29682e+06\n",
            "  log_2 likelihood: -3.31361e+06\n",
            "     cross entropy: 9.73557\n",
            "        perplexity: 852.506\n",
            "      posterior p0: 0.104449\n",
            " posterior al-feat: -0.121262\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.138919 (tension=4)\n",
            "  2  model al-feat: -0.132396 (tension=4.35315)\n",
            "  3  model al-feat: -0.128507 (tension=4.57582)\n",
            "  4  model al-feat: -0.126068 (tension=4.72073)\n",
            "  5  model al-feat: -0.124489 (tension=4.81684)\n",
            "  6  model al-feat: -0.123445 (tension=4.88138)\n",
            "  7  model al-feat: -0.122747 (tension=4.92505)\n",
            "  8  model al-feat: -0.122276 (tension=4.95476)\n",
            "     final tension: 4.97504\n",
            "ITERATION 3\n",
            ".................\n",
            "  log_e likelihood: -1.61138e+06\n",
            "  log_2 likelihood: -2.32473e+06\n",
            "     cross entropy: 6.83018\n",
            "        perplexity: 113.786\n",
            "      posterior p0: 0.0715445\n",
            " posterior al-feat: -0.112448\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.121956 (tension=4.97504)\n",
            "  2  model al-feat: -0.119018 (tension=5.1652)\n",
            "  3  model al-feat: -0.117054 (tension=5.29659)\n",
            "  4  model al-feat: -0.115709 (tension=5.38871)\n",
            "  5  model al-feat: -0.114772 (tension=5.45393)\n",
            "  6  model al-feat: -0.114112 (tension=5.5004)\n",
            "  7  model al-feat: -0.113643 (tension=5.53368)\n",
            "  8  model al-feat: -0.113308 (tension=5.55758)\n",
            "     final tension: 5.57479\n",
            "ITERATION 4\n",
            ".................\n",
            "  log_e likelihood: -1.50101e+06\n",
            "  log_2 likelihood: -2.16551e+06\n",
            "     cross entropy: 6.36238\n",
            "        perplexity: 82.275\n",
            "      posterior p0: 0.0701937\n",
            " posterior al-feat: -0.108257\n",
            "       size counts: 1614\n",
            "  1  model al-feat: -0.113068 (tension=5.57479)\n",
            "  2  model al-feat: -0.111743 (tension=5.67102)\n",
            "  3  model al-feat: -0.110799 (tension=5.74073)\n",
            "  4  model al-feat: -0.11012 (tension=5.79157)\n",
            "  5  model al-feat: -0.109626 (tension=5.82881)\n",
            "  6  model al-feat: -0.109266 (tension=5.85619)\n",
            "  7  model al-feat: -0.109002 (tension=5.87637)\n",
            "  8  model al-feat: -0.108808 (tension=5.89126)\n",
            "     final tension: 5.90227\n",
            "ITERATION 5 (FINAL)\n",
            ".................\n",
            "  log_e likelihood: -1.47175e+06\n",
            "  log_2 likelihood: -2.12328e+06\n",
            "     cross entropy: 6.23832\n",
            "        perplexity: 75.4955\n",
            "      posterior p0: 0\n",
            " posterior al-feat: 0\n",
            "       size counts: 1614\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "! ./atools -i forward.align -j reverse.align -c grow-diag-final-and > result.align"
      ],
      "metadata": {
        "id": "eVvFuFh96Lkm"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! head result.align"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hfMa-iF22H7d",
        "outputId": "4a3e8810-d5cc-42e2-918c-650d020a2586"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0-0 1-1\n",
            "0-0 0-1 1-2\n",
            "0-0 1-1 2-1 2-2 3-3 4-3 5-4\n",
            "0-0 1-0 2-0 2-1 3-1\n",
            "0-0 1-0\n",
            "0-1 1-0 2-1 2-2 3-3 4-3 5-4 7-4 7-5 8-6 9-9 11-7 11-8 14-11 15-11\n",
            "0-0 1-1 2-1 3-2 4-3 5-4 6-4\n",
            "1-0 2-1 2-2 3-2 4-4 4-5 5-5 6-6 7-3 8-3 9-7 10-10 11-8 11-9 13-12 14-11 14-13 15-12 16-16 17-14 18-16 19-17 20-17 21-18 22-19 23-22 24-22 25-23 26-24 27-20 28-21\n",
            "1-0 3-1 4-3 5-3 6-2 7-2 8-4 9-6 10-6 10-7 13-10 14-11 15-8 15-9 16-9 18-10 19-11 20-12 21-14 22-15 23-12 23-13 23-16 24-14 27-17 28-16 29-17\n",
            "0-0 1-0 2-5 3-6 4-7 5-6 6-7 8-9 9-10 10-9 11-11 12-12 13-13 15-9 16-8 17-20 18-14 21-22 22-21 24-15 24-16 25-24 26-29 29-23 30-21 31-28 33-25 34-30 34-31\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# а так было\n",
        "! head Books.en-ru"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coiz8C3T6PED",
        "outputId": "5ce7c09b-311d-4bc0-c611-a829df630def"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Anna Karenina ||| Анна Каренина\n",
            "Leo Tolstoy ||| Толстой Лев Николаевич\n",
            "Vengeance is mine; I will repay. ||| Мне отмщение, и аз воздам\n",
            "VOLUME ONE PART I ||| ЧАСТЬ ПЕРВАЯ\n",
            "CHAPTER I ||| I\n",
            "ALL HAPPY FAMILIES resemble one another, but each unhappy family is unhappy in its own way. ||| Все счастливые семьи похожи друг на друга, каждая несчастливая семья несчастлива по-своему.\n",
            "Everything was upset in the Oblonskys' house. ||| Все смешалось в доме Облонских.\n",
            "The wife had discovered an intrigue between her husband and their former French governess, and declared that she would not continue to live under the same roof with him. ||| Жена узнала, что муж был в связи с бывшею в их доме француженкою-гувернанткой, и объявила мужу, что не может жить с ним в одном доме.\n",
            "This state of things had now lasted for three days, and not only the husband and wife but the rest of the family and the whole household suffered from it. ||| Положение это продолжалось уже третий день и мучительно чувствовалось и самими супругами, и всеми членами семьи, и домочадцами.\n",
            "They all felt that there was no sense in their living together, and that any group of people who had met together by chance at an inn would have had more in common than they. ||| Все члены семьи и домочадцы чувствовали, что нет смысла в их сожительстве и что на каждом постоялом дворе случайно сошедшиеся люди более связаны между собой, чем они, члены семьи и домочадцы Облонских.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно обучить свою нейросеть. Вот тут можно посмотреть на [код-пример](https://github.com/mannefedov/compling_nlp_hse_course/blob/master/notebooks/machine_translation/MT_transformer_tf.ipynb)."
      ],
      "metadata": {
        "id": "SidN4NpLLhEV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### И, конечно, готовое решение\n",
        "\n",
        "Их очень много, но для популярных языков."
      ],
      "metadata": {
        "id": "tjO1rC0kAcKE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "! pip3 install googletrans==3.1.0a0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEttyqlgBEqd",
        "outputId": "92fbca9d-86a6-4151-f149-1faf68b50e6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==3.1.0a0\n",
            "  Downloading googletrans-3.1.0a0.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==3.1.0a0)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (2023.7.22)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hstspreload-2023.1.1-py3-none-any.whl (1.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m22.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==3.1.0a0) (1.3.0)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==3.1.0a0)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-3.1.0a0-py3-none-any.whl size=16352 sha256=80f7850255c08b87dc28f8c64699931b428099c4096b910a5f1a5d7450310b45\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/5d/3c/8477d0af4ca2b8b1308812c09f1930863caeebc762fe265a95\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.4\n",
            "    Uninstalling idna-3.4:\n",
            "      Successfully uninstalled idna-3.4\n",
            "Successfully installed chardet-3.0.4 googletrans-3.1.0a0 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2023.1.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from googletrans import Translator, constants\n",
        "from pprint import pprint"
      ],
      "metadata": {
        "id": "LUp86-8PAjcm"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator()"
      ],
      "metadata": {
        "id": "3A5N2lN_Alur"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translator.translate(\"Mi casa es su casa\")\n",
        "print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I7yUmIUNAzY-",
        "outputId": "f1de3f66-f3bd-49eb-c571-3f919fcc6077"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mi casa es su casa (es) --> My house is your house (en)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translator.translate(\"Вы умеете читать по-арабски?\",\n",
        "                                   src = \"ru\", dest = \"ar\")\n",
        "print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HwDNHTSZBPg2",
        "outputId": "d8bf63d0-aeee-43f9-ee33-5723b1bf7d0b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Вы умеете читать по-арабски? (ru) --> هل تستطيع قراءة اللغة العربية؟ (ar)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pprint(translation.extra_data)"
      ],
      "metadata": {
        "id": "zq_GMVo-B9p2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Также можно переводить набор предложений."
      ],
      "metadata": {
        "id": "de_Y9YiEW-no"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translations = translator.translate([\"Я обожаю ромашки.\", \"Каждый раз, когда я выхожу в поле, я их собираю.\", \"Хотите, подарю вам букетик?\", \"Иначе я подарю его этой девочке. Она их любит.\"], src = \"ru\", dest = \"de\")\n",
        "for translation in translations:\n",
        "    print(\"Translation > \", translation.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ee-h1wbqXB2e",
        "outputId": "148bf2af-9c17-40ee-ebe2-cacf643a81ba"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation >  Ich liebe Gänseblümchen.\n",
            "Translation >  Jedes Mal, wenn ich aufs Feld gehe, sammle ich sie ein.\n",
            "Translation >  Möchten Sie, dass ich Ihnen einen Blumenstrauß schenke?\n",
            "Translation >  Sonst gebe ich es diesem Mädchen. Sie liebt sie.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем также просто попросить определить язык."
      ],
      "metadata": {
        "id": "bNjV5yuFWN7V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "result = translator.detect(\"Welcome to our tutorial!\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0VDl-_LVP99",
        "outputId": "eeec1094-eeef-4be2-8d79-9702acd78dcb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected(lang=en, confidence=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result = translator.detect(\"Kuinka monta karhua sinulla on?\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qiaabaqEXn7B",
        "outputId": "80732515-7c41-4237-eebc-eaec4e1eb37b"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected(lang=fi, confidence=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "translation = translator.translate(\"Kuinka monta karhua sinulla on?\")\n",
        "print(f\"{translation.origin} ({translation.src}) --> {translation.text} ({translation.dest})\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pyw2kvNaX4H2",
        "outputId": "28435b94-120b-4a3a-dfba-04366b185137"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kuinka monta karhua sinulla on? (fi) --> How many bears do you have? (en)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Мы можем попробовать совместить распознавание текста с изображения и перевод."
      ],
      "metadata": {
        "id": "nAh9l4T0Wkox"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr"
      ],
      "metadata": {
        "id": "4hYva36Q3KDy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea46809d-fbd3-498d-ec57-a1dba4fe35dc"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  tesseract-ocr-eng tesseract-ocr-osd\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr tesseract-ocr-eng tesseract-ocr-osd\n",
            "0 upgraded, 3 newly installed, 0 to remove and 18 not upgraded.\n",
            "Need to get 4,816 kB of archives.\n",
            "After this operation, 15.6 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-eng all 1:4.00~git30-7274cfa-1.1 [1,591 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-osd all 1:4.00~git30-7274cfa-1.1 [2,990 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr amd64 4.1.1-2.1build1 [236 kB]\n",
            "Fetched 4,816 kB in 5s (1,008 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 78, <> line 3.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package tesseract-ocr-eng.\n",
            "(Reading database ... 120876 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-eng_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr-osd.\n",
            "Preparing to unpack .../tesseract-ocr-osd_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Selecting previously unselected package tesseract-ocr.\n",
            "Preparing to unpack .../tesseract-ocr_4.1.1-2.1build1_amd64.deb ...\n",
            "Unpacking tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Setting up tesseract-ocr-eng (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-osd (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr (4.1.1-2.1build1) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pytesseract"
      ],
      "metadata": {
        "id": "sX2VyOG73UhU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d76a3ca1-7426-40a5-b47e-cad0a3561c3c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pytesseract\n",
            "  Downloading pytesseract-0.3.10-py3-none-any.whl (14 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (23.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from pytesseract) (9.4.0)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.10\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pytesseract\n",
        "import shutil\n",
        "import os\n",
        "import random\n",
        "try:\n",
        "    from PIL import Image\n",
        "except ImportError:\n",
        "    import Image"
      ],
      "metadata": {
        "id": "8M6iC5-T3WJp"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "from google.colab import files"
      ],
      "metadata": {
        "id": "e4zlpSQaKjLj"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Распознаем текст с картинки."
      ],
      "metadata": {
        "id": "fslvHOLhZkbx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loaded_file = files.upload() # просим пользователя дать картинку"
      ],
      "metadata": {
        "id": "VXaGGqKN3X2u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "1fcf257d-93d1-46cf-b169-0761b31d1774"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-40021352-a4dd-4f87-9983-b5d12e00ae6f\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-40021352-a4dd-4f87-9983-b5d12e00ae6f\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving Rus text_page-0001.jpg to Rus text_page-0001.jpg\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt install tesseract-ocr-rus\n",
        "# либо можно просто написать !sudo apt install tesseract-ocr-all, чтобы установить все языки\n",
        "# это удобно, если вы работает не в google.colab..."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rLZ0RWMY9nax",
        "outputId": "bd8cb1f4-8be7-4ae5-e1f1-f35f67be159b"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "tesseract-ocr-rus is already the newest version (1:4.00~git30-7274cfa-1.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "filename = list(loaded_file.keys())[0]\n",
        "img = cv2.imread(filename) # считываем картинку\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) # делаем её нужной цветовой гаммы\n",
        "print(pytesseract.image_to_osd(img)) # проверяем ориентацию и вообще есть ли распознаваемый текст на картинке"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njTBm-MDw3hT",
        "outputId": "9ea30256-1f7b-4f12-aee4-557c8a4b91d1"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Page number: 0\n",
            "Orientation in degrees: 0\n",
            "Rotate: 0\n",
            "Orientation confidence: 6.64\n",
            "Script: Cyrillic\n",
            "Script confidence: 3.75\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = r'--oem 3 --psm 6'\n",
        "text_image = pytesseract.image_to_string(img, config = config, lang = 'rus')\n",
        "print(text_image)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xjb1FZx6vEyQ",
        "outputId": "295de6e4-2ab9-4336-8291-9c2032fa7890"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "СИНТАКСИС\n",
            "° Предмет синтаксиса.\n",
            "\n",
            "Синтаксис - это раздел грамматики, исслодующий правила соче-\n",
            "тания слов между собой ‚обобщенные значения этих сочетаний, а так-\n",
            "зе типы предложений по их структуре и цели высказывания.В процес-\n",
            "се речи слова связываются друг с другом по определенным правилам.\n",
            "К этим правилам относятся как типы связи слов(проявляющиеся в от-\n",
            "дельных случаях в словоизменительных морфемах), так и порядок их\n",
            "расположения. При монологе речь распадается (разделяется) на от-\n",
            "резки,которые, с одной стороны, обусловлены особенностями функци-\n",
            "онирования органов речи(обычно речь человека ведетоя во время вы-\n",
            "доха, хотя может произноситься и при вдохе),с другой - зависят от\n",
            "смыслового членения.Как правило, членение речи, вызываемое пауза-\n",
            "ми, обусловленное особенностями функционирования органов речи, со-\n",
            "зпадавт оо смысловым, но может и не совпадать.\n",
            "\n",
            "Переходы между паузами, совпадающие со смысловым членением, -\n",
            "назовем их синтагмами, - в свою очередь, разделяются на мелкие от-\n",
            "\n",
            "- резки, характеризующиеся интонацией и смысловой спаянностью. Эти\n",
            "отрезки мы называем словосочетаниями. При диалоге синтагмы, как\n",
            "правило, короче, т.е. состоят из меньшего числа словосочетаний.\n",
            "Под смысловой спаянностью слов нами понимается возможность соче-\n",
            "\n",
            ". таемости слов По их первичным ‘значениям. Г.В.Колшанский пишет:\n",
            "\"Для образования структуры любого словосочетания или предложения\n",
            "необходимо прежде всего наличие некоторого первичного значения в\n",
            "слове, сочетаемость хе его с другими строится на этой базе.Не бу-\n",
            "дет оправданным сочетание: вкусный самолет, деревянный металл и т.\n",
            "д., зубной доктор вместо обычного - зубной врач, - именно в силу\n",
            "семантики сз, хотя структурные признаки - значимости - здесь и\n",
            "присутствуют\" ^. ”\n",
            "\n",
            "Итак, первой задачей синтаксиса является исследование типов\n",
            "словосочетаний. Типы словосочетаний мы определяем по формальным\n",
            "\n",
            ": признакам, т.е. по способам выражения связей олов,а также снисло-\n",
            "вой спаянностью образующих словосочетания слов.Наряду с выяснени-\n",
            "\n",
            ". вы типов словосочетаний даются функции форм слов. Функцию формы\n",
            "\n",
            "т Т.В.К олнанский. Семантика слова в логическом ас-\n",
            "пекте. В сб.: \"Язык и мышление\", М,, 1967, стр. 190.\n",
            "\n",
            "229\n",
            "\f\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Делим на предложения, чтобы потом исправлять и переводить каждое по отдельности. Получится небольшой параллельный \"корпус\".  "
      ],
      "metadata": {
        "id": "IJOzjdZ8Z1sI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install natasha"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5d-CoreZ_SU",
        "outputId": "00571d9b-68c4-4486-887c-175a93681497"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting natasha\n",
            "  Downloading natasha-1.6.0-py3-none-any.whl (34.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.4/34.4 MB\u001b[0m \u001b[31m37.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pymorphy2 (from natasha)\n",
            "  Downloading pymorphy2-0.9.1-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.5/55.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting razdel>=0.5.0 (from natasha)\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Collecting navec>=0.9.0 (from natasha)\n",
            "  Downloading navec-0.10.0-py3-none-any.whl (23 kB)\n",
            "Collecting slovnet>=0.6.0 (from natasha)\n",
            "  Downloading slovnet-0.6.0-py3-none-any.whl (46 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.7/46.7 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting yargy>=0.16.0 (from natasha)\n",
            "  Downloading yargy-0.16.0-py3-none-any.whl (33 kB)\n",
            "Collecting ipymarkup>=0.8.0 (from natasha)\n",
            "  Downloading ipymarkup-0.9.0-py3-none-any.whl (14 kB)\n",
            "Collecting intervaltree>=3 (from ipymarkup>=0.8.0->natasha)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from navec>=0.9.0->natasha) (1.23.5)\n",
            "Collecting dawg-python>=0.7.1 (from pymorphy2->natasha)\n",
            "  Downloading DAWG_Python-0.7.2-py2.py3-none-any.whl (11 kB)\n",
            "Collecting pymorphy2-dicts-ru<3.0,>=2.4 (from pymorphy2->natasha)\n",
            "  Downloading pymorphy2_dicts_ru-2.4.417127.4579844-py2.py3-none-any.whl (8.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docopt>=0.6 (from pymorphy2->natasha)\n",
            "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: sortedcontainers<3.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from intervaltree>=3->ipymarkup>=0.8.0->natasha) (2.4.0)\n",
            "Building wheels for collected packages: docopt, intervaltree\n",
            "  Building wheel for docopt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13705 sha256=b6bffea55228d9779597883c323f306379943928435debdb3e98c7d79facb618\n",
            "  Stored in directory: /root/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26094 sha256=b42bbb92c4689b2ddc166dcf8ac7d1679caff834b88d85726aad324056455367\n",
            "  Stored in directory: /root/.cache/pip/wheels/fa/80/8c/43488a924a046b733b64de3fac99252674c892a4c3801c0a61\n",
            "Successfully built docopt intervaltree\n",
            "Installing collected packages: razdel, pymorphy2-dicts-ru, docopt, dawg-python, pymorphy2, navec, intervaltree, yargy, slovnet, ipymarkup, natasha\n",
            "Successfully installed dawg-python-0.7.2 docopt-0.6.2 intervaltree-3.1.0 ipymarkup-0.9.0 natasha-1.6.0 navec-0.10.0 pymorphy2-0.9.1 pymorphy2-dicts-ru-2.4.417127.4579844 razdel-0.5.0 slovnet-0.6.0 yargy-0.16.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from razdel import sentenize\n",
        "from razdel import tokenize"
      ],
      "metadata": {
        "id": "QyN5A98kaFMy"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences = list(sentenize(text_image))\n",
        "pprint(sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Idx1NDzFaHUR",
        "outputId": "60a2786a-a7aa-4a5c-dc47-3d3c2d895301"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Substring(0, 31, 'СИНТАКСИС\\n° Предмет синтаксиса.'),\n",
            " Substring(33, 292, 'Синтаксис - это раздел грамматики, исслодующий правила соче-\\nтания слов между собой ‚обобщенные значения этих сочетаний, а так-\\nзе типы предложений по их структуре и цели высказывания.В процес-\\nсе речи слова связываются друг с другом по определенным правилам.'),\n",
            " Substring(293, 437, 'К этим правилам относятся как типы связи слов(проявляющиеся в от-\\nдельных случаях в словоизменительных морфемах), так и порядок их\\nрасположения.'),\n",
            " Substring(438, 866, 'При монологе речь распадается (разделяется) на от-\\nрезки,которые, с одной стороны, обусловлены особенностями функци-\\nонирования органов речи(обычно речь человека ведетоя во время вы-\\nдоха, хотя может произноситься и при вдохе),с другой - зависят от\\nсмыслового членения.Как правило, членение речи, вызываемое пауза-\\nми, обусловленное особенностями функционирования органов речи, со-\\nзпадавт оо смысловым, но может и не совпадать.'),\n",
            " Substring(868, 1060, 'Переходы между паузами, совпадающие со смысловым членением, -\\nназовем их синтагмами, - в свою очередь, разделяются на мелкие от-\\n\\n- резки, характеризующиеся интонацией и смысловой спаянностью.'),\n",
            " Substring(1061, 1102, 'Эти\\nотрезки мы называем словосочетаниями.'),\n",
            " Substring(1103, 1192, 'При диалоге синтагмы, как\\nправило, короче, т.е. состоят из меньшего числа словосочетаний.'),\n",
            " Substring(1193, 1302, 'Под смысловой спаянностью слов нами понимается возможность соче-\\n\\n. таемости слов По их первичным ‘значениям.'),\n",
            " Substring(1303, 1734, 'Г.В.Колшанский пишет:\\n\"Для образования структуры любого словосочетания или предложения\\nнеобходимо прежде всего наличие некоторого первичного значения в\\nслове, сочетаемость хе его с другими строится на этой базе.Не бу-\\nдет оправданным сочетание: вкусный самолет, деревянный металл и т.\\nд., зубной доктор вместо обычного - зубной врач, - именно в силу\\nсемантики сз, хотя структурные признаки - значимости - здесь и\\nприсутствуют\" ^. ”'),\n",
            " Substring(1736, 1811, 'Итак, первой задачей синтаксиса является исследование типов\\nсловосочетаний.'),\n",
            " Substring(1812, 2047, 'Типы словосочетаний мы определяем по формальным\\n\\n: признакам, т.е. по способам выражения связей олов,а также снисло-\\nвой спаянностью образующих словосочетания слов.Наряду с выяснени-\\n\\n. вы типов словосочетаний даются функции форм слов.'),\n",
            " Substring(2048, 2081, 'Функцию формы\\n\\nт Т.В.К олнанский.'),\n",
            " Substring(2082, 2121, 'Семантика слова в логическом ас-\\nпекте.'),\n",
            " Substring(2122, 2167, 'В сб.: \"Язык и мышление\", М,, 1967, стр. 190.'),\n",
            " Substring(2169, 2172, '229')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "new_sentences = []\n",
        "for start, end, sentence in list(sentences):\n",
        "  new_sentence = re.sub('\\n|-\\n', '', sentence)\n",
        "  new_sentences.append(new_sentence)\n",
        "print(new_sentences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cBcTihZxa4Uv",
        "outputId": "1f65d773-d6d1-4915-dca1-d22151e39d34"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['СИНТАКСИС° Предмет синтаксиса.', 'Синтаксис - это раздел грамматики, исслодующий правила сочетания слов между собой ‚обобщенные значения этих сочетаний, а такзе типы предложений по их структуре и цели высказывания.В процессе речи слова связываются друг с другом по определенным правилам.', 'К этим правилам относятся как типы связи слов(проявляющиеся в отдельных случаях в словоизменительных морфемах), так и порядок ихрасположения.', 'При монологе речь распадается (разделяется) на отрезки,которые, с одной стороны, обусловлены особенностями функционирования органов речи(обычно речь человека ведетоя во время выдоха, хотя может произноситься и при вдохе),с другой - зависят отсмыслового членения.Как правило, членение речи, вызываемое паузами, обусловленное особенностями функционирования органов речи, созпадавт оо смысловым, но может и не совпадать.', 'Переходы между паузами, совпадающие со смысловым членением, назовем их синтагмами, - в свою очередь, разделяются на мелкие от- резки, характеризующиеся интонацией и смысловой спаянностью.', 'Этиотрезки мы называем словосочетаниями.', 'При диалоге синтагмы, какправило, короче, т.е. состоят из меньшего числа словосочетаний.', 'Под смысловой спаянностью слов нами понимается возможность соче. таемости слов По их первичным ‘значениям.', 'Г.В.Колшанский пишет:\"Для образования структуры любого словосочетания или предложениянеобходимо прежде всего наличие некоторого первичного значения вслове, сочетаемость хе его с другими строится на этой базе.Не будет оправданным сочетание: вкусный самолет, деревянный металл и т.д., зубной доктор вместо обычного - зубной врач, - именно в силусемантики сз, хотя структурные признаки - значимости - здесь иприсутствуют\" ^. ”', 'Итак, первой задачей синтаксиса является исследование типовсловосочетаний.', 'Типы словосочетаний мы определяем по формальным: признакам, т.е. по способам выражения связей олов,а также снисловой спаянностью образующих словосочетания слов.Наряду с выяснени. вы типов словосочетаний даются функции форм слов.', 'Функцию формыт Т.В.К олнанский.', 'Семантика слова в логическом аспекте.', 'В сб.: \"Язык и мышление\", М,, 1967, стр. 190.', '229']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Переводим."
      ],
      "metadata": {
        "id": "31uwh2a9nKLA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "translations = translator.translate(new_sentences, src = \"ru\", dest = \"de\")\n",
        "for translation in translations:\n",
        "    print(\"Translation > \", translation.text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdODmoIxV2pz",
        "outputId": "39eb98b4-4fe8-4264-a896-7ec43b4002a7"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Translation >  SYNTAX° Gegenstand der Syntax.\n",
            "Translation >  Syntax ist ein Abschnitt der Grammatik, der die Regeln für die Kombination von Wörtern untereinander, die verallgemeinerten Bedeutungen dieser Kombinationen sowie die Arten von Sätzen entsprechend ihrer Struktur und dem Zweck der Aussage untersucht. Im Sprechprozess sind Wörter nach bestimmten Regeln miteinander verbunden sind.\n",
            "Translation >  Diese Regeln umfassen sowohl die Art der Verbindungen zwischen Wörtern (die sich in einigen Fällen in Flexionsmorphemen manifestieren) als auch die Reihenfolge ihrer Anordnung.\n",
            "Translation >  Während eines Monologs zerfällt (teilt) die Sprache in Segmente, die einerseits durch die Besonderheiten der Funktionsweise der Sprechorgane bestimmt werden (normalerweise spricht eine Person beim Ausatmen, kann aber auch beim Einatmen ausgesprochen werden), andererseits hängen sie von der semantischen Teilung ab. In der Regel ist die durch Pausen verursachte Teilung der Sprache aufgrund der Besonderheiten der Funktionsweise der Sprachorgane semantisch, darf aber nicht zusammenfallen.\n",
            "Translation >  Übergänge zwischen Pausen, die mit semantischen Unterteilungen, nennen wir sie Syntagmen, zusammenfallen, werden wiederum in kleine Segmente unterteilt, die durch Intonation und semantischen Zusammenhalt gekennzeichnet sind.\n",
            "Translation >  Wir nennen diese Segmente Phrasen.\n",
            "Translation >  Im Dialog sind Syntagmen meist kürzer, d.h. bestehen aus einer kleineren Anzahl von Phrasen.\n",
            "Translation >  Mit semantischem Zusammenhalt von Wörtern meinen wir die Möglichkeit des Zusammenhalts. das Verbergen von Wörtern entsprechend ihrer primären Bedeutung.\n",
            "Translation >  G. V. Kolshansky schreibt: „Um die Struktur einer Phrase oder eines Satzes zu bilden, ist es zunächst notwendig, dass das Wort eine primäre Bedeutung hat; seine Kompatibilität mit anderen basiert auf dieser Grundlage. Die Kombination wird nicht gerechtfertigt: a leckeres Flugzeug, Holzmetall usw., Zahnarzt statt des üblichen - Zahnarzt - gerade im Sinne der Semantik, obwohl hier Strukturmerkmale - Bedeutung - vorhanden sind\" ^. ”\n",
            "Translation >  Die erste Aufgabe der Syntax besteht also darin, die Arten von Wortkombinationen zu untersuchen.\n",
            "Translation >  Wir definieren Phrasentypen anhand formaler Merkmale, d. h. nach den Ausdrucksweisen der Verbindungen von Dosen sowie dem Zusammenhalt von Wörtern, die Wortkombinationen bilden. Zusammen mit der Klarstellung. Ihren Phrasentypen werden Funktionen von Wortformen zugewiesen.\n",
            "Translation >  Funktionsformat T.V.Kolnansky.\n",
            "Translation >  Semantik des Wortes im logischen Aspekt.\n",
            "Translation >  In: „Sprache und Denken“, M, 1967, S. 190.\n",
            "Translation >  229\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Можно написать несложный код, который соотносит каждое предложение с его переводом."
      ],
      "metadata": {
        "id": "r5ObOJBOoUvC"
      }
    }
  ]
}